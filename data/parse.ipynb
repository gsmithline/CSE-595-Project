{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Survey of Machine Learning Techniques Applied to Self Organizing Cellular Networks\n",
      "\n",
      "Abstract: In this paper, a survey of the literature of the past fifteen years involving Machine Learning (ML) algorithms applied to self organizing cellular networks is performed. In order for future networks to overcome the current limitations and address the issues of current cellular systems, it is clear that more intelligence needs to be deployed, so that a fully autonomous and flexible network can be enabled. This paper focuses on the learning perspective of Self Organizing Networks (SON) solutions and provides, not only an overview of the most common ML techniques encountered in cellular networks, but also manages to classify each paper in terms of its learning solution, while also giving some examples. The authors also classify each paper in terms of its self-organizing use-case and discuss how each proposed solution performed. In addition, a comparison between the most commonly found ML algorithms in terms of certain SON metrics is performed and general guidelines on when to choose each ML algorithm for each SON function are proposed. Lastly, this work also provides future research directions and new paradigms that the use of more robust and intelligent algorithms, together with data gathered by operators, can bring to the cellular networks domain and fully enable the concept of SON in the near future.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_title_and_abstract(file_path):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Define the XML namespaces\n",
    "    namespaces = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "\n",
    "    # Extract the title\n",
    "    title_elem = root.find('.//tei:titleStmt/tei:title[@level=\"a\"][@type=\"main\"]', namespaces)\n",
    "    title = title_elem.text if title_elem is not None and title_elem.text else \"Title not found\"\n",
    "\n",
    "    # Extract the abstract\n",
    "    abstract_elem = root.find('.//tei:div/tei:p', namespaces)\n",
    "    abstract = abstract_elem.text if abstract_elem is not None else \"Abstract not found\"\n",
    "\n",
    "    return title, abstract\n",
    "\n",
    "# Usage\n",
    "file_path = \"paper-xml/5a4aef6f17c44a2190f7877f.xml\"\n",
    "title, abstract = extract_title_and_abstract(file_path)\n",
    "\n",
    "print(\"Title:\", title)\n",
    "print(\"\\nAbstract:\", abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8aed5fb7a314996ad464f2e616b3d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7106d851d6443dfb4c9f5bdc87813f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1969ab2085fd4e0d8325f7e56d5f85b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ffcb21835c41d3864060370d670165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc6b72bdecf4c008c53893f60f081b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT embedding shape: torch.Size([1, 768])\n",
      "First few values of the embedding: tensor([-0.6326, -0.5123, -0.9932,  0.4939,  0.8806])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and encode the title and abstract\n",
    "inputs = tokenizer(title + \" \" + abstract, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "\n",
    "# Run the input through BERT\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get the pooled output (representation of the entire input)\n",
    "pooled_output = outputs.pooler_output\n",
    "\n",
    "print(\"BERT embedding shape:\", pooled_output.shape)\n",
    "print(\"First few values of the embedding:\", pooled_output[0][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 689/7541 [00:02<00:24, 275.64it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 7541/7541 [00:24<00:00, 301.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files processed: 7541\n",
      "Abstracts with 512 or fewer tokens: 7535\n",
      "Abstracts with more than 512 tokens: 6\n",
      "Percentage of abstracts over 512 tokens: 0.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text, add_special_tokens=True))\n",
    "\n",
    "def process_xml_files(directory):\n",
    "    under_512 = 0\n",
    "    over_512 = 0\n",
    "    total_files = 0\n",
    "\n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                _, abstract = extract_title_and_abstract(file_path)\n",
    "                token_count = count_tokens(abstract)\n",
    "                \n",
    "                if token_count <= 512:\n",
    "                    under_512 += 1\n",
    "                else:\n",
    "                    over_512 += 1\n",
    "                \n",
    "                total_files += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "    return under_512, over_512, total_files\n",
    "\n",
    "# Process all XML files in the paper-xml directory\n",
    "paper_xml_dir = \"paper-xml\"\n",
    "under_512, over_512, total_files = process_xml_files(paper_xml_dir)\n",
    "\n",
    "print(f\"Total files processed: {total_files}\")\n",
    "print(f\"Abstracts with 512 or fewer tokens: {under_512}\")\n",
    "print(f\"Abstracts with more than 512 tokens: {over_512}\")\n",
    "print(f\"Percentage of abstracts over 512 tokens: {(over_512 / total_files) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7541/7541 [12:52<00:00,  9.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title embeddings saved to 'title_embeddings.csv'\n",
      "Abstract embeddings saved to 'abstract_embeddings.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def embed_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.pooler_output.squeeze().numpy()\n",
    "\n",
    "def process_and_embed_xml_files(directory):\n",
    "    abstract_embeddings = {}\n",
    "    title_embeddings = {}\n",
    "\n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                title, abstract = extract_title_and_abstract(file_path)\n",
    "                \n",
    "                # Embed title\n",
    "                title_embedding = embed_text(title)\n",
    "                title_embeddings[filename[:-4]] = title_embedding\n",
    "                \n",
    "                # Embed abstract\n",
    "                abstract_embedding = embed_text(abstract)\n",
    "                abstract_embeddings[filename[:-4]] = abstract_embedding\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "    return title_embeddings, abstract_embeddings\n",
    "\n",
    "# Process and embed all XML files in the paper-xml directory\n",
    "paper_xml_dir = \"paper-xml\"\n",
    "title_embeddings, abstract_embeddings = process_and_embed_xml_files(paper_xml_dir)\n",
    "\n",
    "# Convert embeddings to DataFrames\n",
    "title_df = pd.DataFrame.from_dict(title_embeddings, orient='index')\n",
    "abstract_df = pd.DataFrame.from_dict(abstract_embeddings, orient='index')\n",
    "\n",
    "# Save embeddings to CSV files\n",
    "title_df.to_csv('title_embeddings.csv')\n",
    "abstract_df.to_csv('abstract_embeddings.csv')\n",
    "\n",
    "print(\"Title embeddings saved to 'title_embeddings.csv'\")\n",
    "print(\"Abstract embeddings saved to 'abstract_embeddings.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of samples: torch.Size([200, 10])\n",
      "Sum of each row: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(200, 10)\n",
    "# Normalize the tensor by row\n",
    "a_normalized = torch.nn.functional.normalize(a, p=1, dim=1)\n",
    "\n",
    "# Define temperature for the concrete distribution\n",
    "temperature = 0.1\n",
    "\n",
    "# Sample from the concrete distribution\n",
    "gumbel_noise = -torch.log(-torch.log(torch.rand_like(a_normalized)))\n",
    "gumbel_max_samples = torch.argmax(torch.log(a_normalized) + gumbel_noise, dim=1)\n",
    "\n",
    "# Convert to one-hot encoding\n",
    "samples = torch.zeros_like(a_normalized)\n",
    "samples.scatter_(1, gumbel_max_samples.unsqueeze(1), 1)\n",
    "\n",
    "print(\"Shape of samples:\", samples.shape)\n",
    "print(\"Sum of each row:\", samples.sum(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
